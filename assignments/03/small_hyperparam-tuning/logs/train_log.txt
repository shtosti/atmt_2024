[2024-11-04 12:33:24] COMMAND: translate.py --data data/en-fr/prepared --dicts data/en-fr/prepared --checkpoint-path assignments/03/small_hyperparam-tuning/checkpoints/checkpoint_last.pt --output assignments/03/small_hyperparam-tuning/translations.txt --batch-size 8
[2024-11-04 12:33:24] Arguments: {'cuda': False, 'data': 'data/en-fr/prepared', 'source_lang': 'fr', 'target_lang': 'en', 'max_tokens': None, 'batch_size': 8, 'train_on_tiny': True, 'arch': 'lstm', 'max_epoch': 10000, 'clip_norm': 2.0, 'lr': 0.003, 'patience': 3, 'log_file': 'assignments/03/small_hyperparam-tuning/logs/train_log.txt', 'save_dir': 'assignments/03/small_hyperparam-tuning/checkpoints', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'decoder_use_lexical_model': 'False', 'device_id': 0, 'seed': 42, 'dicts': 'data/en-fr/prepared', 'checkpoint_path': 'assignments/03/small_hyperparam-tuning/checkpoints/checkpoint_last.pt', 'output': 'assignments/03/small_hyperparam-tuning/translations.txt', 'max_len': 128}
[2024-11-04 12:33:24] Loaded a source dictionary (fr) with 4000 words
[2024-11-04 12:33:24] Loaded a target dictionary (en) with 4000 words
[2024-11-04 12:33:24] Loaded a model from checkpoint assignments/03/small_hyperparam-tuning/checkpoints/checkpoint_last.pt
